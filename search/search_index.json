{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html","title":"\ud83d\udd25 mendableai/firecrawl Changelog: v1.5.0 \u2192 v1.6.0 (2025-03-07)","text":"<p>This release introduces significant advancements, including the integration of the Vercel AI SDK with Ollama support, the alpha version of Deep Research capabilities, and a new batch billing system. Numerous improvements enhance crawling logic, self-hosting options (like Valkey support and configurable ports), and overall system performance through database read replica utilization. Several bug fixes address issues in scraping character sets, extraction token limits, crawling includes/excludes logic, and the JS SDK build process.</p>"},{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html#new-features","title":"\ud83d\udcc8 New Features","text":"<ul> <li>AI SDK Integration:<ul> <li>Migrated core extraction logic to the Vercel AI SDK, enabling broader model support and future flexibility (#1220).</li> <li>Added initial support for using Ollama models for extraction (#1220, #78334e4).</li> <li>Enabled the use of any OpenAI-compatible API endpoint for AI features in self-hosted deployments (#15489be, #1245).</li> </ul> </li> <li>Deep Research (Alpha):<ul> <li>Introduced initial alpha functionality for deep research tasks (#289e351, #1271, #22d4f0d, #1284).</li> <li>Added configuration options for <code>maxUrls</code> and <code>sources</code> (#289e351).</li> <li>Implemented an <code>onSource</code> callback in the SDKs for real-time updates on discovered sources (#22d4f0d, #aa54fd1).</li> </ul> </li> <li>Batch Billing:<ul> <li>Implemented a new system for batch processing of billing events for improved efficiency (#b72e21a, #1264).</li> </ul> </li> <li>Model Support:<ul> <li>Added support for Claude 3.7 in crawling and extraction workflows (#6508afc, #2da6d7b, #bced299, #72eb360).</li> </ul> </li> <li>GitHub Analyzer:<ul> <li>Implemented a new analyzer specifically designed for processing GitHub repositories (#448b44c, #9671e68).</li> </ul> </li> <li>JS SDK:<ul> <li>Added a <code>regexOnFullURL</code> option to the <code>crawl</code> method for more flexible URL matching during crawls (#e1cfe1d).</li> </ul> </li> <li>API:<ul> <li>Added a new endpoint <code>/v1/token-usage</code> to retrieve token usage information (#9ad9478, #1283).</li> </ul> </li> </ul>"},{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html#improvements","title":"\ud83d\udd27 Improvements","text":"<ul> <li>Crawling:<ul> <li>Improved handling of <code>includes</code>/<code>excludes</code> patterns, ensuring empty lists are ignored and initial URLs are checked correctly against patterns (#16c3057, #1223, #e1cfe1d, #1303).</li> <li>Enhanced redirect handling to differentiate between cross-origin and same-origin redirects for more accurate crawling (#e8c698d, #1279).</li> <li>Optimized <code>llmstxt</code> generation by truncating the cache based on the <code>maxUrls</code> limit, improving resource usage for large crawls (#5a18869, #1285).</li> <li>Updated the crawl status WebSocket endpoint (<code>/v1/crawl-status-ws</code>) behavior to ignore errors similarly to the standard <code>/v1/crawl-status</code> endpoint (#8c42b08, #1234).</li> </ul> </li> <li>Self-Hosting:<ul> <li>Added the option to use Valkey (a Redis fork) as the caching backend via <code>docker-compose.yaml</code> (#bfe6a0a, #1228).</li> <li>Allowed configuration of the internal API port through <code>docker-compose.yaml</code> for easier integration in complex network setups (#82adf81).</li> <li>Enabled passing Ollama-related environment variables directly into the Docker Compose setup for easier configuration (#78334e4, #1269).</li> <li>Improved the API Dockerfile for better dependency management and build stages (#76e1f29, #1231, #1232).</li> </ul> </li> <li>AI &amp; Extraction:<ul> <li>Refactored internal AI model adapters for better abstraction and maintainability following the AI SDK migration (#25d9bdb).</li> <li>Removed the <code>zod-to-json-schema</code> dependency as part of the AI SDK migration (#25d9bdb).</li> </ul> </li> <li>API &amp; Infrastructure:<ul> <li>Increased the maximum number of URLs supported by the <code>/v1/map</code> endpoint to 30,000 (#1d3757b).</li> <li>Enhanced logging details for background jobs for better observability (#59d09f5, #0f05203, #ec90aaf, #31df234).</li> <li>Refined rate-limiting logic for API endpoints (#6c51ef4, #72d894c, #1ced546).</li> </ul> </li> <li>Billing:<ul> <li>Added comprehensive integration tests for billing logic and fixed related minor issues (#9ad9478, #1283).</li> </ul> </li> </ul>"},{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Scraping:<ul> <li>Fixed issues with detecting the correct character set (charset) from HTTP headers or meta tags and re-decoding content accordingly, preventing garbled text (#283a3bf, #1221).</li> <li>Improved the regular expression used to parse charset information from HTML <code>meta</code> tags for better accuracy (#7bf04d4, #1265).</li> <li>Increased timeouts when using the stealth proxy option to allow more time for complex pages (#283a3bf - commit message detail).</li> </ul> </li> <li>Extraction:<ul> <li>Resolved errors related to token limits during the LLM extraction process (#5ab86b8, #1236).</li> <li>Fixed handling of AI model responses that incorrectly wrap JSON output within a markdown code block (#4f25f12, #1280).</li> <li>Corrected an issue where the <code>systemPrompt</code> was missing from extraction parameters under certain conditions (#8cfc946).</li> </ul> </li> <li>Crawling:<ul> <li>Ensured that empty <code>includes</code> or <code>excludes</code> arrays provided in crawl requests are correctly ignored (#16c3057, #1223).</li> <li>Improved detection logic for certain strings within web pages (potentially related to ads or specific content patterns) (#c22c87a).</li> </ul> </li> <li>Self-Hosting:<ul> <li>Forced the Docker container host binding to <code>0.0.0.0</code> to prevent environment variable precedence issues that could cause the API to be unreachable (#b88b573, #1225).</li> <li>Fixed the passing of SearXNG parameters in the Docker Compose setup (#51bc775).</li> </ul> </li> <li>JS SDK:<ul> <li>Resolved build issues in the CI pipeline that prevented the JS SDK from being published correctly (#856ec37).</li> <li>Fixed various unspecified issues within the JS SDK for improved stability (#39b6113).</li> </ul> </li> <li>Billing:<ul> <li>Corrected a check related to team identification logic within the credit billing system (#7b05512).</li> </ul> </li> <li>Authentication &amp; Preview:<ul> <li>Addressed issues related to preview token generation and validation (#e6c3f20, #60346ec, #1305).</li> </ul> </li> </ul>"},{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html#performance","title":"\ud83d\ude80 Performance","text":"<ul> <li>Database Optimization:<ul> <li>Implemented read replica routing for Supabase database queries, directing read-heavy operations like authentication checks and crawl status lookups to replicas to reduce load on the primary database (#904e69b, #1274, #67ee266, #8620bf3, #a1e6c13, #783fad9).</li> </ul> </li> <li>Caching:<ul> <li>Implemented a 1-hour cache for ACUC (Authentication Check User Credits) results to reduce database lookups (#44bf592).</li> </ul> </li> </ul>"},{"location":"changelogs/mendableai-firecrawl_v1.5.0_to_v1.6.0.html#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>New Examples:<ul> <li>Added an example demonstrating a Groq-powered web crawler (<code>groq_web_crawler</code>) (#75ac980, #522f2d2).</li> <li>Added an example for a GPT-4.5 powered web crawler (<code>gpt-4.5-web-crawler</code>) (#06cdd98, #ab8dcab).</li> <li>Added an example showcasing a Claude 3.7 web crawler (<code>claude3.7-web-crawler</code>) (#6508afc, #2da6d7b).</li> <li>Added an example for using Claude 3.7 for web extraction (<code>claude3.7-web-extractor</code>) (#bced299, #72eb360).</li> <li>Added an example demonstrating a Gemini-based GitHub repository analyzer (<code>gemini-github-analyzer</code>) (#448b44c, #9671e68).</li> </ul> </li> <li>Self-Hosting Guide:<ul> <li>Updated <code>SELF_HOST.md</code> to include information about the <code>embedding</code> parameter and configuring external AI providers like Ollama (#25d9bdb, #15489be).</li> </ul> </li> <li>API Documentation:<ul> <li>Removed an erroneous <code>required</code> field definition from the API specification (#42e9221, #1282).</li> </ul> </li> </ul> <p>Suggested Filename: <code>ai-sdk_deep-research-alpha_billing_v1.5.0_to_v1.6.0.md</code></p>"}]}